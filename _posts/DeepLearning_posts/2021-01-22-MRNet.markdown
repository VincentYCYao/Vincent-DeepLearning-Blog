---
layout: post
title: "Review: Detecting Abnormalities from Knee MRI Using MR-Net"
date:  2021-01-22 21:00:00 +0800
categories: deeplearning
---

In this blog, the paper [Deep-learning-assisted diagnosis for knee magnetic resonance imaging: Development and retrospective validation of MRNet](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699) is reviewed. This paper was published on PLOS Medicine in 2019.

In this study, the authors  developed a deep learning model for detecting **general abnormalities**, **anterior cruciate ligament (ACL) tears**, and **meniscal tears** on knee MRI exams.

## 1. Background

The interpretation of knee MRI is time-intensive and subject to diagnostic error and variability. An automated system for interpreting knee MRI could prioritize high-risk patients and assist clinicians in making diagnoses.

## 2. Methods

### 2.1 Data

**Datasets:**

> The dataset was split into a training set (to develop the model), a tuning set (to choose among models), and a validation set (to assess the best model and clinical experts).
>
> To form the validation and tuning sets, stratified random sampling was used to ensure that at least 50 positive examples of each label (abnormal, ACL tear, and meniscal tear) were present in each set. 

* training set: 1,130 exams (1,088 patients)
* tuning set: 120 exams (111 patients)
* validation set: 120 exams (113 patients)

![fig1]({{site.baseurl}}/assets/210122_MRNet/img/fig1.png)
**Figure 1.  Experimental setup flowchart.** We retrospectively collected a dataset of 1,370 knee MRI examinations used to develop the model and to assess the model and clinical experts. Labels were prospectively obtained through manual extraction from clinical reports.  The validation set DICOMs correspond to the same exams as the validation set, but the images in the validation set were preprocessed before input to the model.
{: style="text-align: center; color: gray"}

**MRI Sequences:**
* sagittal plane T2-weighted series
* coronal plane T1-weighted series
* axial plane PD-weighted series

### 2.2 Model

#### 2.2.1 Preprocessing

* scaled to 256 × 256 pixels
* converted to Portable Network Graphics (PNG)
* a histogram-based intensity standardization (Ref: [On standardizing the MR image intensity scale](https://pubmed.ncbi.nlm.nih.gov/10571928/))

#### 2.2.2 MRNet

> The primary building block of our prediction system is MRNet, a convolutional neural network (CNN) mapping a 3-dimensional MRI series to a probability. The input to MRNet has dimensions ***s* × 3 × 256 × 256**, where *s* is the number of images in the MRI series (3 is the number of color channels). 
>
> First, each 2-dimensional MRI image slice was passed through a feature extractor based on **AlexNet** to obtain a ***s* × 256 × 7 × 7** tensor containing features for each slice. A **global average pooling layer** was then applied to reduce these features to ***s* × 256**. We then applied **max pooling** across slices to obtain a **256-dimensional vector**, which was passed to a **fully connected layer** and **sigmoid activation function** to obtain a prediction in the 0 to 1 range. We optimized the model using binary **cross-entropy loss**. 
>
> We initialized the weights of the AlexNet portion of the MRNet to values optimized on the **ImageNet** database

**Network structure:**
* feature extractors from AlexNet pre-trained on ImageNet
* global average pooling layer
* max pooling layer
* fully connected layer + sigmoid activation

![fig2]({{site.baseurl}}/assets/210122_MRNet/img/fig2.png)
**Figure 2. MRNet architecture.** The MRNet is a convolutional neural network (CNN) that takes as input a series of MRI images and outputs a classification prediction.  We trained a different MRNet for each task (abnormality, anterior cruciate ligament [ACL] tear, meniscal tear) and series type (sagittal, coronal, axial), resulting in 9 different MRNets (for external validation, we use only the sagittal plane ACL tear MRNet).
{: style="text-align: center; color: gray"}

#### 2.2.3 Class Activation Mappings (CAMs)

> To generate a CAM for an image, we computed a weighted average across the 256 CNN feature maps using weights from the classification layer to obtain a 7 × 7 image. The CAM was then mapped to a color scheme, upsampled to 256 × 256 pixels, and overlaid with the original input image. By using parameters from the final layer of the network to weight the feature maps, more predictive feature maps appear brighter.
>
>  Thus, the brightest areas of the CAMs are the regions that most influence the model’s prediction.

![fig3]({{site.baseurl}}/assets/210122_MRNet/img/fig3.png)
**Figure 3. Class activation mappings for MRNet interpretation.** Class activation mappings (CAMs) highlight which pixels in the images are important for the model’s classification decision.
{: style="text-align: center; color: gray"}

#### 2.2.4 Combining MRNet predictions

> Given predictions from the sagittal T2, coronal T1, and axial PD MRNets on the training set, along with their corresponding original labels, we trained a logistic regression to weight the predictions from the 3 series and generate a single output for each exam. 

The most beneficial series, determined from the coefficients of the fitted logistic regression:
* axial PD for abnormalities and meniscal tears
* coronal T1 for ACL tears

![fig4]({{site.baseurl}}/assets/210122_MRNet/img/fig4.png)
**Figure 4. Combining series predictions using logistic regression.** Each examination contains 3 types of series: sagittal, coronal, and axial. For each task (abnormality, ACL tear, meniscal tear), we trained a logistic regression classifier to combine the 3 probabilities output by the MRNets to produce a single predicted probability for the exam.
{: style="text-align: center; color: gray"}

### 2.3 Evaluation

(a threshold of 0.5 was used to dichotomize the model’s predictions)
* performance measures for the model : sensitivity, specificity, and accuracy, receiver operating characteristic curve (AUC)
* performance measures for general radiologists and orthopedic surgeons:  sensitivity, specificity, and accuracy
* we performed robust hypothesis tests to assess if the clinical experts (as a group) demonstrated statistically significant improvement with model assistance

## 4. Results

* In detecting abnormalities, ACL tears, and meniscal tears, this model achieved area under the receiver operating characteristic curve (AUC) values of 0.937 (95% CI 0.895, 0.980), 0.965 (95% CI 0.938, 0.993), and 0.847 (95% CI 0.780, 0.914), respectively, on the internal validation set
* no significant differences between the performance of the model and that of unassisted general radiologists in detecting abnormalities
* providing model predictions significantly increased clinical experts’ specificity in identifying ACL tears (*p-*value < 0.001; *q-*value = 0.006)

